{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfE7s8msfCLJ",
        "outputId": "17d5f391-02f9-46c3-b083-cdc382569779"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "from keras.layers import Attention\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "50ZzjCRXfbuf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Đọc file csv và gắng index với giá Close\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Data Analyst/Datasets/AMD Historical Data.csv')\n",
        "df1=df.reset_index()['Price']"
      ],
      "metadata": {
        "id": "AGmvO4UVObrT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.shape"
      ],
      "metadata": {
        "id": "xy_NX3-qr5j5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c9ebf92-c99c-41a2-8072-003462ed6a69"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1611,)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Scaler data\n",
        "scaler=MinMaxScaler(feature_range=(0,1))\n",
        "df1=scaler.fit_transform(np.array(df1).reshape(-1,1))"
      ],
      "metadata": {
        "id": "G4CFmOXHlQYf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Chia train test\n",
        "train_size = int(0.7 * len(df1))\n",
        "test_size = int(0.2 * len(df1))\n",
        "val_size = len(df1) - train_size - test_size\n",
        "\n",
        "train_data = df1[:train_size]\n",
        "test_data = df1[train_size:train_size+test_size]\n",
        "val_data = df1[train_size+test_size:]"
      ],
      "metadata": {
        "id": "92qH67_zlRoH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.shape"
      ],
      "metadata": {
        "id": "0OBm0okXsJ0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d1b4b14-209a-4ec4-d473-8f3d3b39fdfd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1127, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Hàm Create Dataset\n",
        "import numpy\n",
        "# convert an array of values into a dataset matrix\n",
        "def create_dataset(dataset, time_step=1):\n",
        "\tdataX, dataY = [], []\n",
        "\tfor i in range(len(dataset)-time_step-1):\n",
        "\t\ta = dataset[i:(i+time_step), 0]   ###i=0, X=0,1,2,3-----99   Y=100 \n",
        "\t\tdataX.append(a)\n",
        "\t\tdataY.append(dataset[i + time_step, 0])\n",
        "\treturn numpy.array(dataX), numpy.array(dataY)"
      ],
      "metadata": {
        "id": "87T5S88bOnNz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#6. Reshape into X=t,t+1,t+2..t+99 and Y=t+100\n",
        "\n",
        "time_step = 100\n",
        "X_train, y_train = create_dataset(train_data, time_step)\n",
        "X_val, yval = create_dataset(val_data, time_step)\n",
        "X_test, ytest = create_dataset(test_data, time_step)"
      ],
      "metadata": {
        "id": "CVIEF8peOsn5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Reshape input to be [samples, time steps, features] which is required for LSTM\n",
        "X_train =X_train.reshape(X_train.shape[0],X_train.shape[1] , 1)\n",
        "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1] , 1)\n",
        "X_val = X_val.reshape(X_val.shape[0],X_val.shape[1] , 1)"
      ],
      "metadata": {
        "id": "GB7U9Ex4lbMC"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "ufvmK5eYtOWS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58a64896-1958-43ee-8cf5-9bc54fbb65a9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1026, 100, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the input shape\n",
        "input_data = Input(shape=(None, 1))\n",
        "\n",
        "# define the LSTM layer\n",
        "lstm_out = LSTM(32, return_sequences=True)(input_data)\n",
        "\n",
        "# define the attention layer\n",
        "attention = Attention()([lstm_out, lstm_out])\n",
        "\n",
        "# define the output layer\n",
        "output = Dense(1)(attention)\n",
        "\n",
        "# create the model\n",
        "model = Model(inputs=input_data, outputs=output)\n",
        "\n",
        "# compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')"
      ],
      "metadata": {
        "id": "KO2XHCtQPAtS"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the model to the training data\n",
        "model.fit(X_train,y_train,validation_data=(X_test,ytest),epochs=100,batch_size=64,verbose=1)"
      ],
      "metadata": {
        "id": "pczEfER3fP74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec60d803-9b5a-44a2-e4e2-3d745452b32e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "17/17 [==============================] - 5s 104ms/step - loss: 0.0493 - val_loss: 0.0527\n",
            "Epoch 2/100\n",
            "17/17 [==============================] - 1s 70ms/step - loss: 0.0377 - val_loss: 0.1152\n",
            "Epoch 3/100\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 0.0332 - val_loss: 0.1580\n",
            "Epoch 4/100\n",
            "17/17 [==============================] - 1s 73ms/step - loss: 0.0322 - val_loss: 0.1708\n",
            "Epoch 5/100\n",
            "17/17 [==============================] - 1s 85ms/step - loss: 0.0318 - val_loss: 0.1933\n",
            "Epoch 6/100\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 0.0318 - val_loss: 0.2008\n",
            "Epoch 7/100\n",
            "17/17 [==============================] - 2s 105ms/step - loss: 0.0318 - val_loss: 0.2049\n",
            "Epoch 8/100\n",
            "17/17 [==============================] - 2s 121ms/step - loss: 0.0320 - val_loss: 0.2006\n",
            "Epoch 9/100\n",
            "17/17 [==============================] - 2s 117ms/step - loss: 0.0318 - val_loss: 0.1908\n",
            "Epoch 10/100\n",
            "17/17 [==============================] - 1s 74ms/step - loss: 0.0320 - val_loss: 0.2084\n",
            "Epoch 11/100\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 0.0320 - val_loss: 0.1901\n",
            "Epoch 12/100\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 0.0319 - val_loss: 0.2073\n",
            "Epoch 13/100\n",
            "17/17 [==============================] - 1s 70ms/step - loss: 0.0319 - val_loss: 0.2111\n",
            "Epoch 14/100\n",
            "17/17 [==============================] - 1s 70ms/step - loss: 0.0318 - val_loss: 0.2042\n",
            "Epoch 15/100\n",
            "17/17 [==============================] - 1s 70ms/step - loss: 0.0318 - val_loss: 0.2169\n",
            "Epoch 16/100\n",
            "17/17 [==============================] - 1s 71ms/step - loss: 0.0318 - val_loss: 0.2026\n",
            "Epoch 17/100\n",
            "17/17 [==============================] - 1s 70ms/step - loss: 0.0319 - val_loss: 0.2191\n",
            "Epoch 18/100\n",
            "17/17 [==============================] - 1s 84ms/step - loss: 0.0324 - val_loss: 0.1883\n",
            "Epoch 19/100\n",
            "17/17 [==============================] - 2s 116ms/step - loss: 0.0318 - val_loss: 0.2022\n",
            "Epoch 20/100\n",
            "17/17 [==============================] - 2s 113ms/step - loss: 0.0320 - val_loss: 0.2004\n",
            "Epoch 21/100\n",
            "17/17 [==============================] - 2s 103ms/step - loss: 0.0318 - val_loss: 0.1643\n",
            "Epoch 22/100\n",
            "17/17 [==============================] - 1s 67ms/step - loss: 0.0332 - val_loss: 0.1692\n",
            "Epoch 23/100\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 0.0320 - val_loss: 0.1746\n",
            "Epoch 24/100\n",
            "17/17 [==============================] - 1s 66ms/step - loss: 0.0319 - val_loss: 0.1897\n",
            "Epoch 25/100\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 0.0319 - val_loss: 0.1864\n",
            "Epoch 26/100\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 0.0318 - val_loss: 0.2051\n",
            "Epoch 27/100\n",
            "17/17 [==============================] - 1s 71ms/step - loss: 0.0319 - val_loss: 0.1894\n",
            "Epoch 28/100\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 0.0318 - val_loss: 0.2043\n",
            "Epoch 29/100\n",
            "17/17 [==============================] - 1s 67ms/step - loss: 0.0319 - val_loss: 0.1966\n",
            "Epoch 30/100\n",
            "17/17 [==============================] - 2s 110ms/step - loss: 0.0317 - val_loss: 0.1940\n",
            "Epoch 31/100\n",
            "17/17 [==============================] - 2s 118ms/step - loss: 0.0320 - val_loss: 0.2028\n",
            "Epoch 32/100\n",
            "17/17 [==============================] - 2s 93ms/step - loss: 0.0320 - val_loss: 0.1991\n",
            "Epoch 33/100\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 0.0317 - val_loss: 0.2065\n",
            "Epoch 34/100\n",
            "17/17 [==============================] - 1s 67ms/step - loss: 0.0317 - val_loss: 0.2137\n",
            "Epoch 35/100\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 0.0319 - val_loss: 0.2083\n",
            "Epoch 36/100\n",
            "17/17 [==============================] - 1s 66ms/step - loss: 0.0318 - val_loss: 0.1915\n",
            "Epoch 37/100\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 0.0319 - val_loss: 0.1920\n",
            "Epoch 38/100\n",
            "17/17 [==============================] - 1s 67ms/step - loss: 0.0319 - val_loss: 0.2021\n",
            "Epoch 39/100\n",
            "17/17 [==============================] - 1s 67ms/step - loss: 0.0319 - val_loss: 0.1942\n",
            "Epoch 40/100\n",
            "17/17 [==============================] - 1s 72ms/step - loss: 0.0318 - val_loss: 0.1933\n",
            "Epoch 41/100\n",
            "17/17 [==============================] - 2s 106ms/step - loss: 0.0318 - val_loss: 0.2064\n",
            "Epoch 42/100\n",
            "17/17 [==============================] - 2s 115ms/step - loss: 0.0318 - val_loss: 0.2039\n",
            "Epoch 43/100\n",
            "17/17 [==============================] - 2s 96ms/step - loss: 0.0317 - val_loss: 0.1893\n",
            "Epoch 44/100\n",
            "17/17 [==============================] - 1s 67ms/step - loss: 0.0328 - val_loss: 0.1738\n",
            "Epoch 45/100\n",
            "17/17 [==============================] - 1s 67ms/step - loss: 0.0320 - val_loss: 0.1896\n",
            "Epoch 46/100\n",
            "17/17 [==============================] - 1s 70ms/step - loss: 0.0319 - val_loss: 0.1873\n",
            "Epoch 47/100\n",
            "17/17 [==============================] - 1s 67ms/step - loss: 0.0319 - val_loss: 0.1879\n",
            "Epoch 48/100\n",
            "17/17 [==============================] - 1s 67ms/step - loss: 0.0320 - val_loss: 0.1948\n",
            "Epoch 49/100\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 0.0320 - val_loss: 0.2072\n",
            "Epoch 50/100\n",
            "17/17 [==============================] - 1s 67ms/step - loss: 0.0318 - val_loss: 0.2016\n",
            "Epoch 51/100\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 0.0319 - val_loss: 0.1958\n",
            "Epoch 52/100\n",
            "17/17 [==============================] - 2s 102ms/step - loss: 0.0322 - val_loss: 0.1896\n",
            "Epoch 53/100\n",
            "17/17 [==============================] - 2s 114ms/step - loss: 0.0320 - val_loss: 0.2069\n",
            "Epoch 54/100\n",
            "17/17 [==============================] - 2s 108ms/step - loss: 0.0318 - val_loss: 0.1873\n",
            "Epoch 55/100\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 0.0319 - val_loss: 0.1826\n",
            "Epoch 56/100\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 0.0321 - val_loss: 0.1959\n",
            "Epoch 57/100\n",
            "17/17 [==============================] - 1s 67ms/step - loss: 0.0319 - val_loss: 0.1778\n",
            "Epoch 58/100\n",
            "17/17 [==============================] - 1s 76ms/step - loss: 0.0318 - val_loss: 0.2022\n",
            "Epoch 59/100\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 0.0318 - val_loss: 0.2027\n",
            "Epoch 60/100\n",
            "17/17 [==============================] - 2s 105ms/step - loss: 0.0318 - val_loss: 0.2051\n",
            "Epoch 61/100\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 0.0319 - val_loss: 0.1993\n",
            "Epoch 62/100\n",
            "17/17 [==============================] - 1s 76ms/step - loss: 0.0318 - val_loss: 0.1941\n",
            "Epoch 63/100\n",
            "17/17 [==============================] - 2s 114ms/step - loss: 0.0318 - val_loss: 0.2037\n",
            "Epoch 64/100\n",
            "17/17 [==============================] - 2s 117ms/step - loss: 0.0317 - val_loss: 0.2137\n",
            "Epoch 65/100\n",
            "17/17 [==============================] - 1s 75ms/step - loss: 0.0318 - val_loss: 0.2043\n",
            "Epoch 66/100\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 0.0318 - val_loss: 0.1981\n",
            "Epoch 67/100\n",
            "17/17 [==============================] - 1s 70ms/step - loss: 0.0318 - val_loss: 0.2061\n",
            "Epoch 68/100\n",
            "17/17 [==============================] - 1s 73ms/step - loss: 0.0320 - val_loss: 0.2049\n",
            "Epoch 69/100\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 0.0318 - val_loss: 0.1939\n",
            "Epoch 70/100\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 0.0318 - val_loss: 0.1992\n",
            "Epoch 71/100\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 0.0319 - val_loss: 0.1974\n",
            "Epoch 72/100\n",
            "17/17 [==============================] - 1s 70ms/step - loss: 0.0317 - val_loss: 0.1962\n",
            "Epoch 73/100\n",
            "17/17 [==============================] - 1s 83ms/step - loss: 0.0317 - val_loss: 0.2082\n",
            "Epoch 74/100\n",
            "17/17 [==============================] - 2s 111ms/step - loss: 0.0318 - val_loss: 0.2102\n",
            "Epoch 75/100\n",
            "17/17 [==============================] - 2s 118ms/step - loss: 0.0319 - val_loss: 0.2047\n",
            "Epoch 76/100\n",
            "17/17 [==============================] - 1s 73ms/step - loss: 0.0318 - val_loss: 0.2035\n",
            "Epoch 77/100\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 0.0318 - val_loss: 0.1973\n",
            "Epoch 78/100\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 0.0317 - val_loss: 0.2001\n",
            "Epoch 79/100\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 0.0319 - val_loss: 0.2012\n",
            "Epoch 80/100\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 0.0317 - val_loss: 0.2102\n",
            "Epoch 81/100\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 0.0320 - val_loss: 0.2006\n",
            "Epoch 82/100\n",
            "17/17 [==============================] - 1s 70ms/step - loss: 0.0317 - val_loss: 0.1966\n",
            "Epoch 83/100\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 0.0317 - val_loss: 0.2038\n",
            "Epoch 84/100\n",
            "17/17 [==============================] - 1s 80ms/step - loss: 0.0318 - val_loss: 0.2060\n",
            "Epoch 85/100\n",
            "17/17 [==============================] - 2s 125ms/step - loss: 0.0318 - val_loss: 0.2053\n",
            "Epoch 86/100\n",
            "17/17 [==============================] - 2s 119ms/step - loss: 0.0318 - val_loss: 0.2027\n",
            "Epoch 87/100\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 0.0317 - val_loss: 0.1981\n",
            "Epoch 88/100\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 0.0318 - val_loss: 0.2006\n",
            "Epoch 89/100\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 0.0318 - val_loss: 0.2006\n",
            "Epoch 90/100\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 0.0317 - val_loss: 0.1969\n",
            "Epoch 91/100\n",
            "17/17 [==============================] - 1s 67ms/step - loss: 0.0317 - val_loss: 0.2106\n",
            "Epoch 92/100\n",
            "17/17 [==============================] - 1s 72ms/step - loss: 0.0319 - val_loss: 0.2015\n",
            "Epoch 93/100\n",
            "17/17 [==============================] - 2s 91ms/step - loss: 0.0321 - val_loss: 0.2033\n",
            "Epoch 94/100\n",
            "17/17 [==============================] - 1s 70ms/step - loss: 0.0318 - val_loss: 0.2102\n",
            "Epoch 95/100\n",
            "17/17 [==============================] - 2s 109ms/step - loss: 0.0319 - val_loss: 0.2031\n",
            "Epoch 96/100\n",
            "17/17 [==============================] - 2s 113ms/step - loss: 0.0318 - val_loss: 0.2038\n",
            "Epoch 97/100\n",
            "17/17 [==============================] - 2s 100ms/step - loss: 0.0318 - val_loss: 0.2064\n",
            "Epoch 98/100\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 0.0321 - val_loss: 0.1837\n",
            "Epoch 99/100\n",
            "17/17 [==============================] - 1s 67ms/step - loss: 0.0318 - val_loss: 0.2017\n",
            "Epoch 100/100\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 0.0319 - val_loss: 0.2022\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3d74316770>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Dự báo dữ liệu test, val\n",
        "train_predict=model.predict(X_train)\n",
        "y_pred=model.predict(X_test)\n",
        "y_pred_val=model.predict(X_val)"
      ],
      "metadata": {
        "id": "i6PiTFj4VJKm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05ee2d69-49a5-4d8d-d213-97bfc8d63ebb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33/33 [==============================] - 1s 15ms/step\n",
            "7/7 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 27ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_predict.shape"
      ],
      "metadata": {
        "id": "VyRUpT1IetoJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ef2c612-24cd-45ef-f100-e6645b645335"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1026, 100, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. Chuẩn hóa dữ liệu y_pred, y_pred_val\n",
        "train_predict=scaler.inverse_transform(train_predict.reshape(-1, 1))\n",
        "y_pred=scaler.inverse_transform(y_pred.reshape(-1, 1))\n",
        "y_pred_val=scaler.inverse_transform(y_pred_val.reshape(-1, 1))"
      ],
      "metadata": {
        "id": "LA7IsFQfV6A7"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 12. Đánh giá độ chính xác thuật toán bằng RMSE\n",
        "valid_rmse = np.sqrt(np.mean((y_pred_val - yval)**2))\n",
        "test_rmse = np.sqrt(np.mean((y_pred - ytest)**2))\n",
        "print('Validation RMSE:', valid_rmse)\n",
        "print('Testing RMSE:', test_rmse)"
      ],
      "metadata": {
        "id": "BZTXYrzlO8K9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aed2c9e6-9faa-48ac-b292-5bdf557fd66f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation RMSE: 39.63020597839024\n",
            "Testing RMSE: 40.970385127246495\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 13. Dự báo 30 ngày tiếp theo\n",
        "x_input=val_data[-time_step:].reshape(1,-1)\n",
        "x_input.shape\n",
        "\n",
        "temp_input=list(x_input)\n",
        "temp_input=temp_input[0].tolist()\n",
        "\n",
        "from numpy import array\n",
        "\n",
        "lst_output=[]\n",
        "n_steps= time_step\n",
        "i=0\n",
        "\n",
        "# # Reshape the input sequence\n",
        "# x_input = x_input.reshape((1, n_steps, 1))\n",
        "\n",
        "while(i<30):\n",
        "    \n",
        "    if(len(temp_input)>time_step):\n",
        "        #print(temp_input)\n",
        "        x_input=np.array(temp_input[1:])\n",
        "        print(\"{} day input {}\".format(i,x_input))\n",
        "        x_input=x_input.reshape(1,-1)\n",
        "        x_input = x_input.reshape((1, n_steps, 1))\n",
        "        #print(x_input)\n",
        "        yhat = model.predict(x_input, verbose=0)\n",
        "        print(\"{} day output {}\".format(i,yhat))\n",
        "        temp_input.extend(yhat[0].tolist())\n",
        "        temp_input=temp_input[1:]\n",
        "        #print(temp_input)\n",
        "        lst_output.extend(yhat.tolist())\n",
        "        i=i+1\n",
        "    else:\n",
        "        x_input = x_input.reshape((1, n_steps,1))\n",
        "        yhat = model.predict(x_input, verbose=0)\n",
        "        print(yhat[0])\n",
        "        temp_input.extend(yhat[0].tolist())\n",
        "        print(len(temp_input))\n",
        "        lst_output.extend(yhat.tolist())\n",
        "        i=i+1\n"
      ],
      "metadata": {
        "id": "zBv_k-5jmdWh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4ab08efa-39b0-4e9e-f076-4d3e215134c1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.20345776]\n",
            " [0.20348771]\n",
            " [0.20351087]\n",
            " [0.20353016]\n",
            " [0.20354511]\n",
            " [0.203557  ]\n",
            " [0.20356712]\n",
            " [0.20357494]\n",
            " [0.20358126]\n",
            " [0.20358549]\n",
            " [0.20358707]\n",
            " [0.20358987]\n",
            " [0.20359595]\n",
            " [0.20359933]\n",
            " [0.20360203]\n",
            " [0.2036042 ]\n",
            " [0.20360604]\n",
            " [0.20360562]\n",
            " [0.203607  ]\n",
            " [0.20361371]\n",
            " [0.20362078]\n",
            " [0.20362456]\n",
            " [0.20362595]\n",
            " [0.20362832]\n",
            " [0.20362933]\n",
            " [0.2036292 ]\n",
            " [0.20362811]\n",
            " [0.20362833]\n",
            " [0.20363013]\n",
            " [0.20363098]\n",
            " [0.20362858]\n",
            " [0.20362593]\n",
            " [0.20362295]\n",
            " [0.20362072]\n",
            " [0.20362094]\n",
            " [0.20362009]\n",
            " [0.20361988]\n",
            " [0.20361957]\n",
            " [0.20361923]\n",
            " [0.20362021]\n",
            " [0.20362158]\n",
            " [0.20362234]\n",
            " [0.20362352]\n",
            " [0.20362628]\n",
            " [0.20362748]\n",
            " [0.20362756]\n",
            " [0.20362724]\n",
            " [0.20363024]\n",
            " [0.20363374]\n",
            " [0.20364033]\n",
            " [0.20364584]\n",
            " [0.20364924]\n",
            " [0.20365123]\n",
            " [0.2036537 ]\n",
            " [0.20365708]\n",
            " [0.20365815]\n",
            " [0.20365822]\n",
            " [0.20365708]\n",
            " [0.20365714]\n",
            " [0.20365824]\n",
            " [0.2036591 ]\n",
            " [0.2036589 ]\n",
            " [0.20365839]\n",
            " [0.20365602]\n",
            " [0.2036543 ]\n",
            " [0.20365484]\n",
            " [0.20365427]\n",
            " [0.20365293]\n",
            " [0.20365179]\n",
            " [0.20365076]\n",
            " [0.20364892]\n",
            " [0.20364748]\n",
            " [0.20364659]\n",
            " [0.20364596]\n",
            " [0.20364456]\n",
            " [0.20364301]\n",
            " [0.20363961]\n",
            " [0.20363848]\n",
            " [0.20363848]\n",
            " [0.20363961]\n",
            " [0.20364065]\n",
            " [0.20364146]\n",
            " [0.20363715]\n",
            " [0.20363708]\n",
            " [0.20363885]\n",
            " [0.20364319]\n",
            " [0.20364633]\n",
            " [0.2036498 ]\n",
            " [0.20365234]\n",
            " [0.20365314]\n",
            " [0.20365502]\n",
            " [0.20365876]\n",
            " [0.20366277]\n",
            " [0.20366812]\n",
            " [0.2036708 ]\n",
            " [0.20367403]\n",
            " [0.20367648]\n",
            " [0.20367835]\n",
            " [0.20368667]\n",
            " [0.20369639]]\n",
            "200\n",
            "1 day input [0.34650216563853525 0.35719910749442185 0.3787242420265126\n",
            " 0.3840399002493765 0.39066806667541676 0.40208688804305026\n",
            " 0.40339939624622656 0.40727129544559654 0.4003150019687623\n",
            " 0.3818086363039769 0.39729623310145684 0.4396902480640504\n",
            " 0.42768079800498754 0.4290589316183226 0.43069956687229294\n",
            " 0.43227457671610453 0.41291508071925453 0.4306339414621342\n",
            " 0.4929124557028481 0.5169969812311328 0.5024281401758761\n",
            " 0.48661241632760205 0.5012468827930174 0.4932405827536422\n",
            " 0.48352802205013773 0.4721748260926631 0.48300301876886725\n",
            " 0.5015093844336527 0.4964562278514241 0.4629872686704292\n",
            " 0.45261845386533667 0.4412652579078619 0.44021525134532086\n",
            " 0.46082163013518834 0.4499278120488253 0.4543903399396246\n",
            " 0.45314345714660714 0.4512403202520016 0.46534978343614647\n",
            " 0.47243732773329833 0.47007481296758097 0.47630922693266836\n",
            " 0.49770311064444156 0.48890930568316054 0.4799842499015619\n",
            " 0.47565297283108027 0.5113531959574746 0.5259876624228901\n",
            " 0.5714004462527891 0.5795379971124819 0.5727785798661242\n",
            " 0.5670035437721486 0.5778317364483527 0.5955505971912325\n",
            " 0.5802598766242288 0.5714660716629478 0.5580128625803911\n",
            " 0.5680535503346895 0.5798004987531171 0.5806536290851818\n",
            " 0.5711379446121538 0.5666097913111958 0.5448877805486285\n",
            " 0.5442971518571991 0.564050400315002 0.554534715841974 0.5433783961149756\n",
            " 0.5418033862711642 0.5395721223257646 0.5272345452159075\n",
            " 0.5266439165244783 0.5276939230870192 0.5288095550597192\n",
            " 0.5177844861530385 0.5121407008793804 0.48739992124950776\n",
            " 0.5014437590234939 0.5112875705473159 0.5239532747079669\n",
            " 0.5260532878330488 0.5274970468565428 0.47309358183488653\n",
            " 0.5058406615041344 0.5270376689854313 0.5611628822680141\n",
            " 0.5612941330883319 0.5741567134794592 0.5746817167607297\n",
            " 0.5626066412915081 0.5766504790654943 0.6034256464102901\n",
            " 0.6183226145163407 0.6457540359627247 0.631907074419215\n",
            " 0.6462134138338365 0.6470009187557422 0.6479852999081244\n",
            " 0.727260795379971 0.7710985693660586 list([0.2034577578306198])\n",
            " list([0.20348770916461945]) list([0.20351086556911469])\n",
            " list([0.20353016257286072]) list([0.20354510843753815])\n",
            " list([0.20355699956417084]) list([0.20356711745262146])\n",
            " list([0.20357494056224823]) list([0.20358125865459442])\n",
            " list([0.20358549058437347]) list([0.20358707010746002])\n",
            " list([0.20358987152576447]) list([0.20359595119953156])\n",
            " list([0.20359933376312256]) list([0.20360203087329865])\n",
            " list([0.20360420644283295]) list([0.2036060392856598])\n",
            " list([0.20360562205314636]) list([0.2036069929599762])\n",
            " list([0.20361371338367462]) list([0.2036207765340805])\n",
            " list([0.20362456142902374]) list([0.20362594723701477])\n",
            " list([0.2036283165216446]) list([0.20362932980060577])\n",
            " list([0.20362919569015503]) list([0.20362810790538788])\n",
            " list([0.2036283314228058]) list([0.20363013446331024])\n",
            " list([0.2036309838294983]) list([0.20362858474254608])\n",
            " list([0.20362593233585358]) list([0.2036229521036148])\n",
            " list([0.20362071692943573]) list([0.20362094044685364])\n",
            " list([0.2036200910806656]) list([0.20361988246440887])\n",
            " list([0.2036195695400238]) list([0.20361922681331635])\n",
            " list([0.20362021028995514]) list([0.20362158119678497])\n",
            " list([0.20362234115600586]) list([0.20362351834774017])\n",
            " list([0.20362627506256104]) list([0.20362748205661774])\n",
            " list([0.2036275565624237]) list([0.20362724363803864])\n",
            " list([0.2036302387714386]) list([0.20363374054431915])\n",
            " list([0.20364032685756683]) list([0.20364584028720856])\n",
            " list([0.20364923775196075]) list([0.20365123450756073])\n",
            " list([0.20365369319915771]) list([0.20365707576274872])\n",
            " list([0.20365814864635468]) list([0.20365822315216064])\n",
            " list([0.20365707576274872]) list([0.2036571353673935])\n",
            " list([0.20365823805332184]) list([0.20365910232067108])\n",
            " list([0.20365889370441437]) list([0.20365838706493378])\n",
            " list([0.20365601778030396]) list([0.20365430414676666])\n",
            " list([0.20365484058856964]) list([0.20365427434444427])\n",
            " list([0.20365293323993683]) list([0.2036517858505249])\n",
            " list([0.20365075767040253]) list([0.20364892482757568])\n",
            " list([0.20364747941493988]) list([0.20364658534526825])\n",
            " list([0.2036459594964981]) list([0.2036445587873459])\n",
            " list([0.20364300906658173]) list([0.20363961160182953])\n",
            " list([0.2036384791135788]) list([0.2036384791135788])\n",
            " list([0.20363961160182953]) list([0.2036406546831131])\n",
            " list([0.20364145934581757]) list([0.20363715291023254])\n",
            " list([0.20363707840442657]) list([0.20363885164260864])\n",
            " list([0.20364318788051605]) list([0.20364633202552795])\n",
            " list([0.20364980399608612]) list([0.20365233719348907])\n",
            " list([0.20365314185619354]) list([0.20365501940250397])\n",
            " list([0.20365875959396362]) list([0.20366276800632477])\n",
            " list([0.20366811752319336]) list([0.20367079973220825])\n",
            " list([0.20367403328418732]) list([0.2036764770746231])\n",
            " list([0.20367835462093353]) list([0.2036866694688797])\n",
            " list([0.2036963850259781])]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-6854ad301121>:21: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  x_input=np.array(temp_input[1:])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-6854ad301121>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{} day input {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mx_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mx_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;31m#print(x_input)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 199 into shape (1,100,1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_input.shape"
      ],
      "metadata": {
        "id": "-fC9Bggiu_zJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 14.Vẽ hình\n",
        "\n",
        "train_data_index = pd.RangeIndex(start=0, stop=train_size, step=1)\n",
        "plt.plot(scaler.inverse_transform(train_data))\n",
        "test_data_index = pd.RangeIndex(start=train_size, stop=train_size+test_size, step=1)\n",
        "plt.plot(test_data_index,scaler.inverse_transform(test_data))\n",
        "test_data_index = pd.RangeIndex(start=train_size+101, stop=train_size+test_size, step=1)\n",
        "plt.plot(test_data_index,(y_pred))\n",
        "val_data_index = pd.RangeIndex(start=train_size+test_size, stop=train_size+test_size+val_size, step=1)\n",
        "plt.plot(val_data_index,scaler.inverse_transform(val_data))\n",
        "val_data_index = pd.RangeIndex(start=train_size+test_size+101, stop=train_size+test_size+val_size, step=1)\n",
        "plt.plot(val_data_index,y_pred_val)\n",
        "prediect_data_index = pd.RangeIndex(start=len(df1)-1, stop=len(df1)+29, step=1)\n",
        "plt.plot(prediect_data_index,scaler.inverse_transform(lst_output))\n",
        "plt.legend(['Train','Test','Predict','Validate','ValidatePred','Predict30days'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5Cp1uOpoO0Yg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}